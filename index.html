<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Whisper - Real-time Transcription</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background-color: #1a1a1a;
            color: #e0e0e0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        .header {
            background-color: #2a2a2a;
            padding: 1rem 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header h1 {
            font-size: 1.5rem;
            font-weight: 600;
            color: #ffffff;
        }

        .container {
            flex: 1;
            padding: 2rem;
            max-width: 1200px;
            width: 100%;
            margin: 0 auto;
        }

        .status-bar {
            background-color: #2a2a2a;
            border-radius: 8px;
            padding: 1rem 1.5rem;
            margin-bottom: 2rem;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: wrap;
            gap: 1rem;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: #666;
            transition: background-color 0.3s ease;
        }

        .status-dot.active {
            background-color: #4CAF50;
            animation: pulse 2s infinite;
        }

        .status-dot.error {
            background-color: #f44336;
        }

        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(76, 175, 80, 0.7);
            }
            70% {
                box-shadow: 0 0 0 10px rgba(76, 175, 80, 0);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(76, 175, 80, 0);
            }
        }

        .audio-level {
            width: 100px;
            height: 6px;
            background-color: #333;
            border-radius: 3px;
            overflow: hidden;
            margin-left: 1rem;
        }

        .audio-level-bar {
            height: 100%;
            background-color: #4CAF50;
            width: 0%;
            transition: width 0.1s ease;
        }

        .api-key-section {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .api-key-input {
            background-color: #1a1a1a;
            border: 1px solid #444;
            color: #e0e0e0;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            font-size: 0.9rem;
            width: 300px;
        }

        .api-key-input:focus {
            outline: none;
            border-color: #4CAF50;
        }

        .save-key-btn, .record-btn, .mode-toggle-btn {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s ease;
        }

        .save-key-btn:hover, .record-btn:hover, .mode-toggle-btn:hover {
            background-color: #45a049;
        }

        .record-btn.recording {
            background-color: #f44336;
        }

        .record-btn.recording:hover {
            background-color: #d32f2f;
        }

        .mode-toggle-btn.on-demand {
            background-color: #FF9800;
        }

        .mode-toggle-btn.on-demand:hover {
            background-color: #F57C00;
        }

        .recording-controls {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .transcription-area {
            background-color: #2a2a2a;
            border-radius: 8px;
            padding: 1.5rem;
            height: calc(100vh - 300px);
            min-height: 400px;
            display: flex;
            flex-direction: column;
        }

        .transcription-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }

        .transcription-header h2 {
            font-size: 1.2rem;
            font-weight: 500;
        }

        .button-group {
            display: flex;
            gap: 0.5rem;
        }

        .clear-btn, .debug-btn {
            background-color: #666;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s ease;
        }

        .clear-btn:hover, .debug-btn:hover {
            background-color: #555;
        }

        .transcription-content {
            background-color: #1a1a1a;
            border: 1px solid #444;
            border-radius: 4px;
            padding: 1rem;
            flex: 1;
            overflow-y: auto;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.95rem;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .transcription-content::-webkit-scrollbar {
            width: 8px;
        }

        .transcription-content::-webkit-scrollbar-track {
            background: #1a1a1a;
        }

        .transcription-content::-webkit-scrollbar-thumb {
            background: #666;
            border-radius: 4px;
        }

        .transcription-content::-webkit-scrollbar-thumb:hover {
            background: #888;
        }

        .error-message {
            background-color: rgba(244, 67, 54, 0.1);
            border: 1px solid #f44336;
            color: #ff8a80;
            padding: 1rem;
            border-radius: 4px;
            margin-bottom: 1rem;
            display: none;
        }

        .debug-info {
            background-color: rgba(255, 193, 7, 0.1);
            border: 1px solid #FFC107;
            color: #FFD54F;
            padding: 1rem;
            border-radius: 4px;
            margin-bottom: 1rem;
            font-size: 0.85rem;
            font-family: monospace;
            display: none;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            .api-key-input {
                width: 200px;
            }

            .status-bar {
                padding: 1rem;
                flex-direction: column;
                gap: 1rem;
            }

            .recording-controls {
                order: -1;
            }

            .transcription-area {
                height: calc(100vh - 400px);
                min-height: 300px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üéôÔ∏è Web Whisper</h1>
    </div>

    <div class="container">
        <div class="status-bar">
            <div class="status-indicator">
                <div class="status-dot" id="statusDot"></div>
                <span id="statusText">Inactive</span>
                <div class="audio-level">
                    <div class="audio-level-bar" id="audioLevelBar"></div>
                </div>
            </div>
            <div class="recording-controls">
                <button id="modeToggleBtn" class="mode-toggle-btn">Always-On</button>
                <button id="recordBtn" class="record-btn" style="display: none;">üéôÔ∏è Record</button>
            </div>
            <div class="api-key-section">
                <input 
                    type="password" 
                    id="apiKeyInput" 
                    class="api-key-input" 
                    placeholder="Enter OpenAI API Key"
                >
                <button id="saveKeyBtn" class="save-key-btn">Save</button>
            </div>
        </div>

        <div class="error-message" id="errorMessage"></div>
        <div class="debug-info" id="debugInfo"></div>

        <div class="transcription-area">
            <div class="transcription-header">
                <h2>Transcription History</h2>
                <div class="button-group">
                    <button id="debugBtn" class="debug-btn">Debug</button>
                    <button id="clearBtn" class="clear-btn">Clear</button>
                </div>
            </div>
            <div class="transcription-content" id="transcriptionContent">
                Waiting for microphone access...
            </div>
        </div>
    </div>

    <script>
        class WhisperTranscriber {
            constructor() {
                this.apiKey = localStorage.getItem('openai_api_key') || '';
                this.recordingMode = localStorage.getItem('recording_mode') || 'always-on'; // 'always-on' or 'on-demand'
                this.mediaRecorder = null;
                this.isRecording = false;
                this.transcriptionHistory = '';
                this.audioContext = null;
                this.analyser = null;
                this.microphone = null;
                this.scriptProcessor = null;
                this.debugMode = false;
                this.audioStream = null;
                this.monitoringStarted = false;
                
                // Audio recording settings
                this.sampleRate = 16000;
                this.chunkDuration = 5000; // 5 seconds chunks for faster response
                this.silenceThreshold = 0.02; // Higher threshold to avoid noise
                this.silenceDuration = 1000; // 1 second of silence
                this.minSpeechDuration = 500; // Minimum 0.5s of speech
                
                // Voice activity detection
                this.speechStartTime = null;
                this.lastSoundTime = Date.now();
                this.consecutiveSilentFrames = 0;
                this.silentFramesThreshold = 10; // Need 10 silent frames to confirm silence
                
                // Buffer for continuous recording
                this.audioBuffer = [];
                this.isProcessing = false;
                this.lastChunkTime = Date.now();
                
                this.initializeElements();
                this.setupEventListeners();
                this.checkApiKey();
            }

            initializeElements() {
                this.statusDot = document.getElementById('statusDot');
                this.statusText = document.getElementById('statusText');
                this.apiKeyInput = document.getElementById('apiKeyInput');
                this.saveKeyBtn = document.getElementById('saveKeyBtn');
                this.clearBtn = document.getElementById('clearBtn');
                this.debugBtn = document.getElementById('debugBtn');
                this.modeToggleBtn = document.getElementById('modeToggleBtn');
                this.recordBtn = document.getElementById('recordBtn');
                this.transcriptionContent = document.getElementById('transcriptionContent');
                this.errorMessage = document.getElementById('errorMessage');
                this.audioLevelBar = document.getElementById('audioLevelBar');
                this.debugInfo = document.getElementById('debugInfo');

                if (this.apiKey) {
                    this.apiKeyInput.value = this.apiKey;
                }
                
                this.updateRecordingModeUI();
            }

            setupEventListeners() {
                // API Key management
                this.saveKeyBtn.addEventListener('click', () => this.saveApiKey());
                this.apiKeyInput.addEventListener('keypress', (e) => {
                    if (e.key === 'Enter') this.saveApiKey();
                });

                // Clear button
                this.clearBtn.addEventListener('click', () => this.clearTranscription());
                
                // Debug button
                this.debugBtn.addEventListener('click', () => this.toggleDebug());

                // Recording mode toggle
                this.modeToggleBtn.addEventListener('click', () => this.toggleRecordingMode());
                
                // Manual record button
                this.recordBtn.addEventListener('click', () => this.toggleRecording());

                // Tab visibility
                document.addEventListener('visibilitychange', () => {
                    if (document.hidden) {
                        if (this.recordingMode === 'always-on') {
                            this.stopRecording();
                        }
                    } else if (this.apiKey && this.recordingMode === 'always-on') {
                        if (this.isRecording && !this.monitoringStarted) {
                            this.monitoringStarted = true;
                            this.monitorAudioLevel();
                        }
                        this.startRecording();
                    }
                });

                // Window focus
                window.addEventListener('focus', () => {
                    if (this.apiKey && !this.isRecording && this.recordingMode === 'always-on') {
                        this.startRecording();
                    }
                });

                window.addEventListener('blur', () => {
                    if (this.recordingMode === 'always-on') {
                        this.stopRecording();
                    }
                });
            }

            toggleRecordingMode() {
                this.recordingMode = this.recordingMode === 'always-on' ? 'on-demand' : 'always-on';
                localStorage.setItem('recording_mode', this.recordingMode);
                
                // Stop current recording when switching modes
                if (this.isRecording) {
                    this.stopRecording();
                }
                
                this.updateRecordingModeUI();
                
                // Auto-start recording if switching to always-on mode
                if (this.recordingMode === 'always-on' && this.apiKey) {
                    this.startRecording();
                }
            }

            toggleRecording() {
                if (this.recordingMode !== 'on-demand') return;
                
                if (!this.apiKey) {
                    this.showError('Please enter your OpenAI API key first');
                    return;
                }
                
                if (this.isRecording) {
                    this.stopRecording();
                } else {
                    this.startRecording();
                }
            }

            updateRecordingModeUI() {
                if (this.recordingMode === 'always-on') {
                    this.modeToggleBtn.textContent = 'Always-On';
                    this.modeToggleBtn.className = 'mode-toggle-btn';
                    this.recordBtn.style.display = 'none';
                } else {
                    this.modeToggleBtn.textContent = 'On-Demand';
                    this.modeToggleBtn.className = 'mode-toggle-btn on-demand';
                    this.recordBtn.style.display = 'inline-block';
                    this.updateRecordButtonState();
                }
            }

            updateRecordButtonState() {
                if (this.recordingMode === 'on-demand') {
                    if (this.isRecording) {
                        this.recordBtn.textContent = '‚èπÔ∏è Stop';
                        this.recordBtn.className = 'record-btn recording';
                    } else {
                        this.recordBtn.textContent = 'üéôÔ∏è Record';
                        this.recordBtn.className = 'record-btn';
                    }
                }
            }

            toggleDebug() {
                this.debugMode = !this.debugMode;
                this.debugInfo.style.display = this.debugMode ? 'block' : 'none';
                this.debugBtn.textContent = this.debugMode ? 'Hide Debug' : 'Debug';
            }

            updateDebugInfo(info) {
                if (this.debugMode) {
                    this.debugInfo.textContent = `Debug Info:\n${info}`;
                }
            }

            checkApiKey() {
                if (this.apiKey) {
                    if (this.recordingMode === 'always-on') {
                        this.startRecording();
                    } else {
                        this.updateStatus('Ready', 'inactive');
                        this.transcriptionContent.textContent = 'On-demand mode. Click "Record" to start transcribing.';
                    }
                } else {
                    this.updateStatus('No API Key', 'error');
                    this.transcriptionContent.textContent = 'Please enter your OpenAI API key to start transcribing.';
                }
            }

            saveApiKey() {
                const key = this.apiKeyInput.value.trim();
                if (!key) {
                    this.showError('Please enter a valid API key');
                    return;
                }

                this.apiKey = key;
                localStorage.setItem('openai_api_key', key);
                this.hideError();
                
                if (this.recordingMode === 'always-on') {
                    this.transcriptionContent.textContent = 'API key saved. Starting transcription...';
                    this.startRecording();
                } else {
                    this.transcriptionContent.textContent = 'API key saved. On-demand mode - click "Record" to start transcribing.';
                    this.updateStatus('Ready', 'inactive');
                }
            }

            async startRecording() {
                if (this.isRecording || !this.apiKey) return;

                try {
                    // Request microphone
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                            sampleRate: this.sampleRate
                        } 
                    });
                    
                    this.audioStream = stream;
                    
                    // Setup audio context
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: this.sampleRate
                    });
                    
                    if (this.audioContext.state === 'suspended') {
                        await this.audioContext.resume();
                    }
                    
                    // Create nodes
                    this.analyser = this.audioContext.createAnalyser();
                    this.analyser.fftSize = 2048;
                    this.analyser.smoothingTimeConstant = 0.8;
                    
                    this.scriptProcessor = this.audioContext.createScriptProcessor(4096, 1, 1);
                    
                    this.microphone = this.audioContext.createMediaStreamSource(stream);
                    this.microphone.connect(this.analyser);
                    this.analyser.connect(this.scriptProcessor);
                    this.scriptProcessor.connect(this.audioContext.destination);
                    
                    // Process audio data
                    this.scriptProcessor.onaudioprocess = (event) => {
                        if (!this.isRecording) return;
                        
                        const inputData = event.inputBuffer.getChannelData(0);
                        const audioData = new Float32Array(inputData);
                        
                        // Calculate RMS for voice detection
                        const rms = this.calculateRMS(audioData);
                        const isSpeaking = rms > this.silenceThreshold;
                        
                        if (isSpeaking) {
                            // Reset silence counter
                            this.consecutiveSilentFrames = 0;
                            this.lastSoundTime = Date.now();
                            
                            // Mark speech start
                            if (!this.speechStartTime) {
                                this.speechStartTime = Date.now();
                            }
                            
                            // Add audio to buffer
                            this.audioBuffer.push(audioData);
                        } else {
                            // Count silent frames
                            this.consecutiveSilentFrames++;
                            
                            // If we were speaking, keep recording during short pauses
                            if (this.speechStartTime && this.consecutiveSilentFrames < this.silentFramesThreshold) {
                                this.audioBuffer.push(audioData);
                            }
                        }
                        
                        // Check if we should process
                        this.checkAndProcessAudio();
                    };
                    
                    this.isRecording = true;
                    this.updateStatus('Recording', 'active');
                    
                    // Update record button state for on-demand mode
                    if (this.recordingMode === 'on-demand') {
                        this.updateRecordButtonState();
                    }
                    
                    // Start monitoring levels
                    if (!this.monitoringStarted) {
                        this.monitoringStarted = true;
                        setTimeout(() => {
                            this.monitorAudioLevel();
                        }, 100);
                    }
                    
                    if (this.transcriptionHistory === '') {
                        this.transcriptionContent.textContent = 'Listening...';
                    }

                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    this.showError(`Failed to access microphone: ${error.message}`);
                    this.updateStatus('Error', 'error');
                    
                    // Reset record button state if recording failed to start
                    if (this.recordingMode === 'on-demand') {
                        this.updateRecordButtonState();
                    }
                }
            }

            calculateRMS(data) {
                let sum = 0;
                for (let i = 0; i < data.length; i++) {
                    sum += data[i] * data[i];
                }
                return Math.sqrt(sum / data.length);
            }

            checkAndProcessAudio() {
                const now = Date.now();
                const timeSinceChunk = now - this.lastChunkTime;
                const speechDuration = this.speechStartTime ? now - this.speechStartTime : 0;
                const bufferDuration = (this.audioBuffer.length * 4096) / this.sampleRate * 1000;
                
                // Process if:
                // 1. We have speech and detected end of speech (silence)
                // 2. Buffer is getting too long (5 seconds)
                // 3. It's been too long since last chunk (prevent hanging)
                const shouldProcess = this.audioBuffer.length > 0 && !this.isProcessing && (
                    (this.speechStartTime && 
                     this.consecutiveSilentFrames >= this.silentFramesThreshold && 
                     speechDuration > this.minSpeechDuration) ||
                    bufferDuration > this.chunkDuration ||
                    (timeSinceChunk > 10000 && this.speechStartTime) // 10s failsafe
                );
                
                if (shouldProcess) {
                    this.processAudioBuffer();
                }
            }

            async processAudioBuffer() {
                if (this.audioBuffer.length === 0 || this.isProcessing) return;
                
                this.isProcessing = true;
                this.lastChunkTime = Date.now();
                this.speechStartTime = null;
                this.consecutiveSilentFrames = 0;
                
                try {
                    // Combine all audio chunks
                    const totalLength = this.audioBuffer.reduce((acc, chunk) => acc + chunk.length, 0);
                    const combinedBuffer = new Float32Array(totalLength);
                    let offset = 0;
                    
                    for (const chunk of this.audioBuffer) {
                        combinedBuffer.set(chunk, offset);
                        offset += chunk.length;
                    }
                    
                    // Clear buffer
                    this.audioBuffer = [];
                    
                    // Skip if audio is too quiet overall
                    const overallRMS = this.calculateRMS(combinedBuffer);
                    if (overallRMS < this.silenceThreshold * 0.5) {
                        this.isProcessing = false;
                        return;
                    }
                    
                    // Convert to WAV
                    const wavBlob = this.createWAVBlob(combinedBuffer);
                    
                    this.updateDebugInfo(
                        `Processing audio:\n` +
                        `Duration: ${(totalLength / this.sampleRate).toFixed(1)}s\n` +
                        `Size: ${(wavBlob.size / 1024).toFixed(1)} KB\n` +
                        `RMS: ${overallRMS.toFixed(4)}\n` +
                        `Format: WAV (${this.sampleRate}Hz)`
                    );
                    
                    // Transcribe
                    await this.transcribeAudio(wavBlob);
                    
                } catch (error) {
                    console.error('Error processing audio:', error);
                    this.showError(`Processing error: ${error.message}`);
                } finally {
                    this.isProcessing = false;
                }
            }

            createWAVBlob(audioData) {
                const length = audioData.length;
                const arrayBuffer = new ArrayBuffer(44 + length * 2);
                const view = new DataView(arrayBuffer);
                
                // WAV header
                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };
                
                writeString(0, 'RIFF');
                view.setUint32(4, 36 + length * 2, true);
                writeString(8, 'WAVE');
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, 1, true);
                view.setUint32(24, this.sampleRate, true);
                view.setUint32(28, this.sampleRate * 2, true);
                view.setUint16(32, 2, true);
                view.setUint16(34, 16, true);
                writeString(36, 'data');
                view.setUint32(40, length * 2, true);
                
                // Convert float32 to int16
                let offset = 44;
                for (let i = 0; i < length; i++) {
                    const sample = Math.max(-1, Math.min(1, audioData[i]));
                    view.setInt16(offset, sample * 0x7FFF, true);
                    offset += 2;
                }
                
                return new Blob([arrayBuffer], { type: 'audio/wav' });
            }

            async transcribeAudio(audioBlob) {
                try {
                    const audioFile = new File([audioBlob], 'audio.wav', { 
                        type: 'audio/wav',
                        lastModified: Date.now()
                    });

                    const formData = new FormData();
                    formData.append('file', audioFile);
                    formData.append('model', 'whisper-1');
                    formData.append('response_format', 'json');
                    formData.append('language', 'en');
                    // Add temperature to reduce hallucinations
                    formData.append('temperature', '0');

                    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${this.apiKey}`
                        },
                        body: formData
                    });

                    if (!response.ok) {
                        const error = await response.json();
                        throw new Error(error.error?.message || 'Transcription failed');
                    }

                    const result = await response.json();
                    const transcription = result.text;
                    
                    // Better filtering of noise/hallucinations
                    if (transcription && transcription.trim()) {
                        // Filter out common Whisper hallucinations
                        const filtered = transcription.trim();
                        if (!filtered.match(/^[\.\s]+$/) && // Not just dots/spaces
                            !filtered.match(/^\[.*\]$/) && // Not just brackets
                            !filtered.match(/^\(.*\)$/) && // Not just parentheses
                            !filtered.match(/^(you|You|Mm-hmm|Uh-huh|Yeah|Okay|Thanks|Thank you)\.?$/) && // Not just filler
                            filtered.length > 1) { // Not single character
                            this.addTranscription(filtered);
                        }
                    }

                } catch (error) {
                    console.error('Transcription error:', error);
                    this.showError(`Transcription error: ${error.message}`);
                    this.updateDebugInfo(`Error: ${error.message}`);
                }
            }

            monitorAudioLevel() {
                if (!this.isRecording || !this.audioContext) {
                    this.audioLevelBar.style.width = '0%';
                    this.monitoringStarted = false;
                    return;
                }

                if (!this.analyser) {
                    setTimeout(() => this.monitorAudioLevel(), 100);
                    return;
                }

                try {
                    const bufferLength = this.analyser.fftSize;
                    const dataArray = new Uint8Array(bufferLength);
                    this.analyser.getByteTimeDomainData(dataArray);
                    
                    // Calculate RMS
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        const normalized = (dataArray[i] - 128) / 128;
                        sum += normalized * normalized;
                    }
                    const rms = Math.sqrt(sum / bufferLength);
                    
                    // Convert to percentage
                    const percentage = Math.min(100, rms * 500);
                    this.audioLevelBar.style.width = percentage + '%';
                    
                    // Update debug info
                    if (this.debugMode) {
                        const bufferDuration = this.audioBuffer.length > 0 ? 
                            ((this.audioBuffer.length * 4096) / this.sampleRate).toFixed(1) : '0';
                        const timeSinceSound = ((Date.now() - this.lastSoundTime) / 1000).toFixed(1);
                        
                        this.updateDebugInfo(
                            `Audio Level: ${percentage.toFixed(1)}%\n` +
                            `RMS: ${rms.toFixed(4)}\n` +
                            `Speaking: ${rms > this.silenceThreshold}\n` +
                            `Silent Frames: ${this.consecutiveSilentFrames}\n` +
                            `Buffer Duration: ${bufferDuration}s\n` +
                            `Time Since Sound: ${timeSinceSound}s\n` +
                            `Processing: ${this.isProcessing ? 'Yes' : 'No'}`
                        );
                    }
                } catch (error) {
                    console.error('Error in audio monitoring:', error);
                }
                
                if (this.isRecording) {
                    requestAnimationFrame(() => this.monitorAudioLevel());
                }
            }

            stopRecording() {
                if (!this.isRecording) return;

                this.isRecording = false;
                this.monitoringStarted = false;
                
                // Process any remaining audio
                if (this.audioBuffer.length > 0 && this.speechStartTime) {
                    this.processAudioBuffer();
                }
                
                if (this.audioStream) {
                    this.audioStream.getTracks().forEach(track => track.stop());
                    this.audioStream = null;
                }

                if (this.scriptProcessor) {
                    this.scriptProcessor.disconnect();
                    this.scriptProcessor.onaudioprocess = null;
                    this.scriptProcessor = null;
                }

                if (this.microphone) {
                    this.microphone.disconnect();
                    this.microphone = null;
                }

                if (this.analyser) {
                    this.analyser.disconnect();
                    this.analyser = null;
                }

                if (this.audioContext && this.audioContext.state !== 'closed') {
                    this.audioContext.close();
                    this.audioContext = null;
                }

                // Clear audio data
                this.audioBuffer = [];
                this.speechStartTime = null;

                this.audioLevelBar.style.width = '0%';
                this.updateStatus('Stopped', 'inactive');
                this.updateDebugInfo('Recording stopped');
                
                // Update record button state for on-demand mode
                if (this.recordingMode === 'on-demand') {
                    this.updateRecordButtonState();
                }
            }

            addTranscription(text) {
                const timestamp = new Date().toLocaleTimeString();
                const formattedText = `[${timestamp}] ${text}\n\n`;
                
                this.transcriptionHistory += formattedText;
                this.transcriptionContent.textContent = this.transcriptionHistory;
                
                // Auto-scroll to bottom
                this.transcriptionContent.scrollTop = this.transcriptionContent.scrollHeight;
            }

            clearTranscription() {
                this.transcriptionHistory = '';
                if (this.isRecording) {
                    this.transcriptionContent.textContent = 'Listening...';
                } else if (this.recordingMode === 'on-demand') {
                    this.transcriptionContent.textContent = 'Cleared. Click "Record" to start transcribing.';
                } else {
                    this.transcriptionContent.textContent = 'Cleared. Start recording to see new transcriptions.';
                }
            }

            updateStatus(text, state) {
                this.statusText.textContent = text;
                this.statusDot.className = `status-dot ${state}`;
            }

            showError(message) {
                this.errorMessage.textContent = message;
                this.errorMessage.style.display = 'block';
                setTimeout(() => this.hideError(), 5000);
            }

            hideError() {
                this.errorMessage.style.display = 'none';
            }
        }

        // Initialize the app
        const app = new WhisperTranscriber();
    </script>
</body>
</html>
