<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Whisper - Real-time Transcription</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background-color: #1a1a1a;
            color: #e0e0e0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        .header {
            background-color: #2a2a2a;
            padding: 1rem 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header h1 {
            font-size: 1.5rem;
            font-weight: 600;
            color: #ffffff;
        }

        .container {
            flex: 1;
            padding: 2rem;
            max-width: 1200px;
            width: 100%;
            margin: 0 auto;
        }

        .status-bar {
            background-color: #2a2a2a;
            border-radius: 8px;
            padding: 1rem 1.5rem;
            margin-bottom: 2rem;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: wrap;
            gap: 1rem;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: #666;
            transition: background-color 0.3s ease;
        }

        .status-dot.active {
            background-color: #4CAF50;
            animation: pulse 2s infinite;
        }

        .status-dot.error {
            background-color: #f44336;
        }

        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(76, 175, 80, 0.7);
            }
            70% {
                box-shadow: 0 0 0 10px rgba(76, 175, 80, 0);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(76, 175, 80, 0);
            }
        }

        .audio-level {
            width: 100px;
            height: 6px;
            background-color: #333;
            border-radius: 3px;
            overflow: hidden;
            margin-left: 1rem;
        }

        .audio-level-bar {
            height: 100%;
            background-color: #4CAF50;
            width: 0%;
            transition: width 0.1s ease;
        }

        .api-key-section {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .api-key-input {
            background-color: #1a1a1a;
            border: 1px solid #444;
            color: #e0e0e0;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            font-size: 0.9rem;
            width: 300px;
        }

        .api-key-input:focus {
            outline: none;
            border-color: #4CAF50;
        }

        .save-key-btn {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s ease;
        }

        .save-key-btn:hover {
            background-color: #45a049;
        }

        .transcription-area {
            background-color: #2a2a2a;
            border-radius: 8px;
            padding: 1.5rem;
            height: calc(100vh - 300px);
            min-height: 400px;
            display: flex;
            flex-direction: column;
        }

        .transcription-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }

        .transcription-header h2 {
            font-size: 1.2rem;
            font-weight: 500;
        }

        .button-group {
            display: flex;
            gap: 0.5rem;
        }

        .clear-btn, .debug-btn {
            background-color: #666;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s ease;
        }

        .clear-btn:hover, .debug-btn:hover {
            background-color: #555;
        }

        .transcription-content {
            background-color: #1a1a1a;
            border: 1px solid #444;
            border-radius: 4px;
            padding: 1rem;
            flex: 1;
            overflow-y: auto;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.95rem;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .transcription-content::-webkit-scrollbar {
            width: 8px;
        }

        .transcription-content::-webkit-scrollbar-track {
            background: #1a1a1a;
        }

        .transcription-content::-webkit-scrollbar-thumb {
            background: #666;
            border-radius: 4px;
        }

        .transcription-content::-webkit-scrollbar-thumb:hover {
            background: #888;
        }

        .error-message {
            background-color: rgba(244, 67, 54, 0.1);
            border: 1px solid #f44336;
            color: #ff8a80;
            padding: 1rem;
            border-radius: 4px;
            margin-bottom: 1rem;
            display: none;
        }

        .debug-info {
            background-color: rgba(255, 193, 7, 0.1);
            border: 1px solid #FFC107;
            color: #FFD54F;
            padding: 1rem;
            border-radius: 4px;
            margin-bottom: 1rem;
            font-size: 0.85rem;
            font-family: monospace;
            display: none;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            .api-key-input {
                width: 200px;
            }

            .status-bar {
                padding: 1rem;
            }

            .transcription-area {
                height: calc(100vh - 350px);
                min-height: 300px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üéôÔ∏è Web Whisper</h1>
    </div>

    <div class="container">
        <div class="status-bar">
            <div class="status-indicator">
                <div class="status-dot" id="statusDot"></div>
                <span id="statusText">Inactive</span>
                <div class="audio-level">
                    <div class="audio-level-bar" id="audioLevelBar"></div>
                </div>
            </div>
            <div class="api-key-section">
                <input 
                    type="password" 
                    id="apiKeyInput" 
                    class="api-key-input" 
                    placeholder="Enter OpenAI API Key"
                >
                <button id="saveKeyBtn" class="save-key-btn">Save</button>
            </div>
        </div>

        <div class="error-message" id="errorMessage"></div>
        <div class="debug-info" id="debugInfo"></div>

        <div class="transcription-area">
            <div class="transcription-header">
                <h2>Transcription History</h2>
                <div class="button-group">
                    <button id="debugBtn" class="debug-btn">Debug</button>
                    <button id="clearBtn" class="clear-btn">Clear</button>
                </div>
            </div>
            <div class="transcription-content" id="transcriptionContent">
                Waiting for microphone access...
            </div>
        </div>
    </div>

    <script>
        class WhisperTranscriber {
            constructor() {
                this.apiKey = localStorage.getItem('openai_api_key') || '';
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.isRecording = false;
                this.transcriptionHistory = '';
                this.audioContext = null;
                this.analyser = null;
                this.microphone = null;
                this.scriptProcessor = null;
                this.hasSpokenInChunk = false;
                this.chunkStartTime = null;
                this.debugMode = false;
                this.audioStream = null;
                
                this.initializeElements();
                this.setupEventListeners();
                this.checkApiKey();
            }

            initializeElements() {
                this.statusDot = document.getElementById('statusDot');
                this.statusText = document.getElementById('statusText');
                this.apiKeyInput = document.getElementById('apiKeyInput');
                this.saveKeyBtn = document.getElementById('saveKeyBtn');
                this.clearBtn = document.getElementById('clearBtn');
                this.debugBtn = document.getElementById('debugBtn');
                this.transcriptionContent = document.getElementById('transcriptionContent');
                this.errorMessage = document.getElementById('errorMessage');
                this.audioLevelBar = document.getElementById('audioLevelBar');
                this.debugInfo = document.getElementById('debugInfo');

                if (this.apiKey) {
                    this.apiKeyInput.value = this.apiKey;
                }
            }

            setupEventListeners() {
                // API Key management
                this.saveKeyBtn.addEventListener('click', () => this.saveApiKey());
                this.apiKeyInput.addEventListener('keypress', (e) => {
                    if (e.key === 'Enter') this.saveApiKey();
                });

                // Clear button
                this.clearBtn.addEventListener('click', () => this.clearTranscription());
                
                // Debug button
                this.debugBtn.addEventListener('click', () => this.toggleDebug());

                // Tab visibility
                document.addEventListener('visibilitychange', () => {
                    if (document.hidden) {
                        this.stopRecording();
                    } else if (this.apiKey) {
                        this.startRecording();
                    }
                });

                // Window focus
                window.addEventListener('focus', () => {
                    if (this.apiKey && !this.isRecording) {
                        this.startRecording();
                    }
                });

                window.addEventListener('blur', () => {
                    this.stopRecording();
                });
            }

            toggleDebug() {
                this.debugMode = !this.debugMode;
                this.debugInfo.style.display = this.debugMode ? 'block' : 'none';
                this.debugBtn.textContent = this.debugMode ? 'Hide Debug' : 'Debug';
            }

            updateDebugInfo(info) {
                if (this.debugMode) {
                    this.debugInfo.textContent = `Debug Info:\n${info}`;
                }
            }

            checkApiKey() {
                if (this.apiKey) {
                    this.startRecording();
                } else {
                    this.updateStatus('No API Key', 'error');
                    this.transcriptionContent.textContent = 'Please enter your OpenAI API key to start transcribing.';
                }
            }

            saveApiKey() {
                const key = this.apiKeyInput.value.trim();
                if (!key) {
                    this.showError('Please enter a valid API key');
                    return;
                }

                this.apiKey = key;
                localStorage.setItem('openai_api_key', key);
                this.hideError();
                this.transcriptionContent.textContent = 'API key saved. Starting transcription...';
                this.startRecording();
            }

            async startRecording() {
                if (this.isRecording || !this.apiKey) return;

                try {
                    // Request microphone with specific constraints
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                            sampleRate: 48000
                        } 
                    });
                    
                    this.audioStream = stream;
                    
                    // Setup audio context for level monitoring
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.analyser = this.audioContext.createAnalyser();
                    this.microphone = this.audioContext.createMediaStreamSource(stream);
                    
                    // Create script processor for real-time audio analysis
                    this.scriptProcessor = this.audioContext.createScriptProcessor(2048, 1, 1);
                    
                    // Connect the nodes
                    this.microphone.connect(this.analyser);
                    this.analyser.connect(this.scriptProcessor);
                    this.scriptProcessor.connect(this.audioContext.destination);
                    
                    // Setup analyser
                    this.analyser.fftSize = 1024;
                    this.analyser.smoothingTimeConstant = 0.3;
                    
                    // Monitor audio levels
                    this.monitorAudioLevel();

                    // Get supported mime type
                    const mimeType = this.getSupportedMimeType();
                    this.updateDebugInfo(`Mime type: ${mimeType}\nAudio Context State: ${this.audioContext.state}`);
                    
                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: mimeType
                    });

                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                            this.updateDebugInfo(`Chunk received: ${event.data.size} bytes\nTotal chunks: ${this.audioChunks.length}`);
                        }
                    };

                    this.mediaRecorder.onstop = async () => {
                        if (this.audioChunks.length > 0 && this.hasSpokenInChunk) {
                            const audioBlob = new Blob(this.audioChunks, { type: mimeType });
                            this.audioChunks = [];
                            
                            const chunkDuration = Date.now() - this.chunkStartTime;
                            this.updateDebugInfo(`Sending audio: ${audioBlob.size} bytes\nDuration: ${chunkDuration}ms`);
                            
                            if (chunkDuration > 500) { // At least 0.5 seconds
                                await this.transcribeAudio(audioBlob, mimeType);
                            }
                        } else {
                            this.audioChunks = [];
                            this.updateDebugInfo(`Skipped silent chunk`);
                        }
                        this.hasSpokenInChunk = false;
                    };

                    this.isRecording = true;
                    this.mediaRecorder.start();
                    this.chunkStartTime = Date.now();
                    this.updateStatus('Recording', 'active');
                    
                    // Record in 10-second chunks
                    this.recordingInterval = setInterval(() => {
                        if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                            this.mediaRecorder.stop();
                            setTimeout(() => {
                                if (this.isRecording && this.mediaRecorder) {
                                    this.audioChunks = [];
                                    this.hasSpokenInChunk = false;
                                    this.chunkStartTime = Date.now();
                                    this.mediaRecorder.start();
                                }
                            }, 100);
                        }
                    }, 10000);

                    if (this.transcriptionHistory === '') {
                        this.transcriptionContent.textContent = 'Listening... (Speak clearly and wait a moment for transcription)';
                    }

                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    this.showError(`Failed to access microphone: ${error.message}`);
                    this.updateStatus('Error', 'error');
                }
            }

            getSupportedMimeType() {
                const types = [
                    'audio/webm;codecs=opus',
                    'audio/webm',
                    'audio/ogg;codecs=opus',
                    'audio/mp4',
                ];
                
                for (const type of types) {
                    if (MediaRecorder.isTypeSupported(type)) {
                        console.log('Using mime type:', type);
                        return type;
                    }
                }
                
                return 'audio/webm'; // fallback
            }

            monitorAudioLevel() {
                if (!this.analyser || !this.isRecording) {
                    this.audioLevelBar.style.width = '0%';
                    return;
                }

                const bufferLength = this.analyser.fftSize;
                const dataArray = new Uint8Array(bufferLength);
                this.analyser.getByteTimeDomainData(dataArray);
                
                // Calculate RMS (Root Mean Square) for better volume representation
                let sum = 0;
                for (let i = 0; i < bufferLength; i++) {
                    const normalized = (dataArray[i] - 128) / 128;
                    sum += normalized * normalized;
                }
                const rms = Math.sqrt(sum / bufferLength);
                
                // Convert to percentage (0-100)
                const percentage = Math.min(100, rms * 500);
                this.audioLevelBar.style.width = percentage + '%';
                
                // Detect if there's significant audio (speaking)
                if (percentage > 5) { // Lower threshold for better detection
                    this.hasSpokenInChunk = true;
                }
                
                // Update debug info
                if (this.debugMode) {
                    const maxValue = Math.max(...dataArray);
                    const minValue = Math.min(...dataArray);
                    this.updateDebugInfo(`Audio Level: ${percentage.toFixed(1)}%\nRMS: ${rms.toFixed(4)}\nMax: ${maxValue}, Min: ${minValue}\nHas spoken: ${this.hasSpokenInChunk}`);
                }
                
                // Continue monitoring
                requestAnimationFrame(() => this.monitorAudioLevel());
            }

            stopRecording() {
                if (!this.isRecording) return;

                this.isRecording = false;
                
                if (this.recordingInterval) {
                    clearInterval(this.recordingInterval);
                    this.recordingInterval = null;
                }

                if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
                    this.mediaRecorder.stop();
                }

                if (this.audioStream) {
                    this.audioStream.getTracks().forEach(track => track.stop());
                    this.audioStream = null;
                }

                if (this.scriptProcessor) {
                    this.scriptProcessor.disconnect();
                    this.scriptProcessor = null;
                }

                if (this.microphone) {
                    this.microphone.disconnect();
                    this.microphone = null;
                }

                if (this.analyser) {
                    this.analyser.disconnect();
                    this.analyser = null;
                }

                if (this.audioContext) {
                    this.audioContext.close();
                    this.audioContext = null;
                }

                this.audioLevelBar.style.width = '0%';
                this.updateStatus('Stopped', 'inactive');
                this.updateDebugInfo('Recording stopped');
            }

            async transcribeAudio(audioBlob, mimeType) {
                try {
                    // Convert to a format Whisper definitely supports
                    const audioFile = new File([audioBlob], 'audio.webm', { 
                        type: mimeType 
                    });

                    const formData = new FormData();
                    formData.append('file', audioFile);
                    formData.append('model', 'whisper-1');
                    formData.append('response_format', 'json');
                    formData.append('language', 'en');

                    this.updateDebugInfo(`Sending to Whisper API...\nFile size: ${audioFile.size} bytes`);

                    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${this.apiKey}`
                        },
                        body: formData
                    });

                    if (!response.ok) {
                        const error = await response.json();
                        throw new Error(error.error?.message || 'Transcription failed');
                    }

                    const result = await response.json();
                    const transcription = result.text;
                    
                    this.updateDebugInfo(`Received: "${transcription}"`);
                    
                    // Filter out common noise transcriptions
                    if (transcription && 
                        transcription.trim() && 
                        transcription.trim().length > 2 &&
                        !transcription.match(/^(you|You|Yeah|yeah|Hmm|hmm|Mm|mm|Um|um|Uh|uh)\.?$/)) {
                        this.addTranscription(transcription);
                    }

                } catch (error) {
                    console.error('Transcription error:', error);
                    this.showError(`Transcription error: ${error.message}`);
                    this.updateDebugInfo(`Error: ${error.message}`);
                }
            }

            addTranscription(text) {
                const timestamp = new Date().toLocaleTimeString();
                const formattedText = `[${timestamp}] ${text.trim()}\n\n`;
                
                this.transcriptionHistory += formattedText;
                this.transcriptionContent.textContent = this.transcriptionHistory;
                
                // Auto-scroll to bottom
                this.transcriptionContent.scrollTop = this.transcriptionContent.scrollHeight;
            }

            clearTranscription() {
                this.transcriptionHistory = '';
                this.transcriptionContent.textContent = this.isRecording ? 'Listening... (Speak clearly and wait a moment for transcription)' : 'Cleared. Start recording to see new transcriptions.';
            }

            updateStatus(text, state) {
                this.statusText.textContent = text;
                this.statusDot.className = `status-dot ${state}`;
            }

            showError(message) {
                this.errorMessage.textContent = message;
                this.errorMessage.style.display = 'block';
            }

            hideError() {
                this.errorMessage.style.display = 'none';
            }
        }

        // Initialize the app when the page loads
        const app = new WhisperTranscriber();
    </script>
</body>
</html>
